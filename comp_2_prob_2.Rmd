---
subtitle: "TMA4268 Statistical Learning V2019"
title: "Compulsory exercise 2: Group 31"
author: "Ingrid Sofie Skjetne and Johannes Voll Kolst√∏"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
 # html_document
  pdf_document
---
  
```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      cache=TRUE, size="scriptsize",fig.width=4, fig.height=3)
```

```{r rpackages,eval=TRUE,echo=FALSE}
# install.packages("knitr") #probably already installed
# install.packages("rmarkdown") #probably already installed
# install.packages("ggplot2") #plotting with ggplot
# install.packages("ggfortify")  
# install.packages("MASS")  
# install.packages("dplyr")  
library(knitr)
library(rmarkdown)
library(ggplot2)
library(ggfortify)
library(MASS)
library(dplyr)
library(ISLR)
```

# Problem 2

## a)
i) False
ii) False
iii) True
iv) True

## b)
The basis functions for a cubic spline with knots at the qaurtiles $q_1, q_2, q_3$ of variable $X$ are $\{1, X, X^2, X^3, h(X, q_1),  h(X, q_2), h(X, q_3)\}$,
where the functions $h(X, q_i)$ are truncated third power functions of $X$, allowing for discontinuities in the third derivative at the knots. They are defined as
$$h(X, q_i) = 
\begin{cases}
(X - q_i)^3,&\quad q_i \leq X, \\
0,&\quad X \leq q_i.
\end{cases}
$$
In total we have $4 + K = 7$ degrees of freedom with these seven basis functions.

## c)

```{r task2c, eval=TRUE, echo=TRUE, fig.width=8, fig.height=10}
# Loading College data:
set.seed(1)
train.ind = sample(1:nrow(College), 0.5 * nrow(College))
college.train = College[train.ind, ]
college.test = College[-train.ind, ]
# str(College)

predictors = c("Private", "Room.Board", "Terminal", "perc.alumni", "Expend", "Grad.Rate")
response = c("Outstate")
College_2 = select(College, predictors, response)
names(College_2)

# Generating the six plots of the response Outstate versus the six predictors:
color_data = College_2$Private
p_Private = ggplot(College_2, aes(x = Private, y = Outstate, color=color_data)) + 
  geom_point() + theme(legend.position="top")
p_Room.Board = ggplot(College_2, aes(x = Room.Board, y = Outstate, color=color_data)) + 
  geom_point() + theme(legend.position="none")
p_Terminal = ggplot(College_2, aes(x = Terminal, y = Outstate, color=color_data)) + 
  geom_point() + theme(legend.position="none")
p_perc.alumni = ggplot(College_2, aes(x = perc.alumni, y = Outstate, color=color_data)) + 
  geom_point() + theme(legend.position="none") 
p_Expend = ggplot(College_2, aes(x = Expend, y = Outstate, color=color_data)) + 
  geom_point() + theme(legend.position="none")
p_Grad.Rate = ggplot(College_2, aes(x = Grad.Rate, y = Outstate, color=color_data)) + 
  geom_point() + theme(legend.position="none")

# Plotting the six plots in a 3X2-grid:
gridExtra::grid.arrange(p_Private, p_Room.Board, p_Terminal, p_perc.alumni, p_Expend, p_Grad.Rate, 
                        nrow=3, ncol=2)
```

By looking at the above plots of `Outstate` versus the six predictors `Private`, `Room.Board`, `Terminal`, `perc.alumni`, `Expend` and `Grad.Rate` there are several  interesting features present. The relationship between `Outstate` and `Terminal` seems reasonably linear and without need for a non-linear transformation, although we observe increasing variance with increasing predictor value. This also seems to be the case for the relationship between `Oustate` and the qualitative variable `Private`, as there appears to be an increase in the average `Outstate` for private colleges compared to public ones, but the variance in `Outstate` is also increased for the private colleges.  

The plot of `Outstate` versus `Grad.Rate` appears to have a clear linear relationship, and the variance appears more constant over the range of `Grad.Rate` values. In comparison, the relationship between `Expend` and `Outstate` appears linear until `Expend` increases above `20 000`, after which the `Outstate` values level off and vary greatly. In such a case a non-linear transformation of `Expend` seems beneficial for regression purposes, in order to avoid many the outliers with high leverage which would appear in a linear regression.

From the plot of `Outstate` versus `Terminal` it seems that there is a non-linear relationship between them. Especially the relationship between `Outstate` and the `Terminal` values for private colleges looks more quadratic than linear, and in need of a non-linear transformation. And even the public colleges appear to have a non-linear relationship between `Outstate` and `Terminal`, if not as clear.

Lastly, the relationship between `Outstate` and `perc.alumni` appears weak, and therefore an overly flexible non-linear basis function might be too flexible to give good predictive results. Therefore it does not appear beneficial to apply a non-linear transform to `per.alumni` before regression onto `Outstate`.

## d)


## e)

## f)

## g)

## h)